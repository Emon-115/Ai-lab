# -*- coding: utf-8 -*-
"""Ai_KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1af_0VX5Cp8sHuNiMuHx2trk8Gay2D4jA
"""

import numpy as np
import random



class KNN_Classifier:

    # already implemented
    def read_data(self, filename):

        full_dataset = np.genfromtxt(filename, delimiter=",")
        np.random.shuffle(full_dataset)
        # print(full_dataset)

        self.x_train_data = []
        self.y_train_data = []
        self.x_test_data = []
        self.y_test_data = []

        for eachdata in full_dataset.tolist():
            rand_num = random.random()  # 0.0<=rand_num<1.0 0.0 0.1 0.2 0.3 0.4  ........1.0 0 1
            if rand_num < 0.8:
                self.x_train_data.append(eachdata[2:6])
                self.y_train_data.append(eachdata[0])
            else:
                self.x_test_data.append(eachdata[2:6])
                self.y_test_data.append(eachdata[0])

        # print(self.x_train_data, "\n")
        # print(self.y_train_data, "\n")
        # print(len(self.x_train_data), "\n")
        # # print(self.validation_data,"\n")
        # print(self.x_test_data, "\n")
        # print(self.y_test_data)


    def main_knn(self, k):
        dataset = self.x_test_data.copy()

        right_classify_cnt = 0  # for accuracy calculation

        for i in range(len(dataset)):
            actual_class = self.y_test_data[i] 
            # print(actual_class)
            predicted_class = self.predict_each_data(dataset[i], k)

            if actual_class == predicted_class:
                right_classify_cnt += 1

        accuracy = right_classify_cnt / len(dataset) * 100
        return accuracy

    # just implement this method
    def predict_each_data(self, datapoint, k):
        np_training_data = np.array(self.x_train_data, dtype=float)  # converting training_data into numpy array.
        np_datapoint = np.array(datapoint, dtype=float)  # converting datapoint(validation) into nparray.
        # print(np_datapoint)
        np_datapoint = np_datapoint.reshape(1, 4)
        # print(np_datapoint)

        distancearr = np.sqrt(((np_training_data[:, [0, 1, 2, 3]] - np_datapoint[:, [0, 1, 2, 3]]) ** 2).sum(axis=1))
        # print("distance array","\n", distancearr)
        # print("sorted index array","\n", np.argsort(distancearr))
        sort_distance_index = np.argsort(distancearr)   

        pclasslist = []

        for i in range(k):
            pclasslist.append(self.y_train_data[sort_distance_index[i]])  # finding the decision/class of those nearest data using their index.
            # print("predicted class list \n", pclasslist)

        # print(pclasslist)
        count1 = pclasslist.count(0)  # total count of decision class 0  >>how many decisions are 0 in predict_class_list;
        count2 = pclasslist.count(1)  # total count of decision class 1
        count3 = pclasslist.count(2)  # total count of decision class 2
        temp = [count1, count2, count3]
        # print(count1, count2, count3, temp)
        temp = np.array(temp)  # taking the decision count into a numpy arrray.
        # print(temp)
        # print(temp.argmax())
        return temp.argmax()  # return the maxcount index >>>index is same as decision here.


# If your implementation is correct then the following code will work properly.
classifier = KNN_Classifier()
classifier.read_data("iris.csv")


k=5
test_accuracy = classifier.main_knn(k)
print("Test Accuracy: ", test_accuracy)